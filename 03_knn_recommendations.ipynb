{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9599a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucune session Spark active à arrêter. C'est parfait.\n",
      "--- Démarrage de la SparkSession pour les recommandations KNN ---\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "try:\n",
    "    spark.stop()\n",
    "    print(\"Ancienne session Spark arrêtée avec succès.\")\n",
    "except:\n",
    "    print(\"Aucune session Spark active à arrêter. C'est parfait.\")\n",
    "\n",
    "# --- Initialisation de la SparkSession ---\n",
    "print(\"--- Démarrage de la SparkSession pour les recommandations KNN ---\")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KNNRecommendations\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.hadoop.io.native.lib.available\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.maxResults\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24082a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tentative de chargement MANUEL des facteurs ---\n",
      "✅ SUCCÈS ! Les userFactors et itemFactors ont été chargés manuellement.\n",
      "Aperçu des userFactors :\n",
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "|  3|[-0.36637914, -0....|\n",
      "| 13|[-0.47874132, -0....|\n",
      "| 33|[-0.554954, 0.378...|\n",
      "| 43|[-0.39298496, 0.4...|\n",
      "| 53|[-0.62480736, 0.5...|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Aperçu des itemFactors :\n",
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "|  5|[-0.3952559, 0.13...|\n",
      "| 15|[-0.4015493, 0.11...|\n",
      "| 25|[-0.3550805, 0.26...|\n",
      "| 35|[-0.30379027, 0.0...|\n",
      "| 45|[-0.36853588, 0.3...|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assurez-vous que votre SparkSession est créée comme dans le test précédent qui fonctionnait\n",
    "\n",
    "# Chemin vers votre DOSSIER de modèle ALS sauvegardé\n",
    "# Utilisez la syntaxe file:/// et les slashes\n",
    "path_to_als_model = rf\"file:///C:\\Users\\arthu\\Desktop\\spank movies\\ml-32m\\models\\best_als_global_model\"\n",
    "\n",
    "try:\n",
    "    print(\"--- Tentative de chargement MANUEL des facteurs ---\")\n",
    "\n",
    "    # On lit directement les sous-dossiers userFactors et itemFactors\n",
    "    user_factors = spark.read.parquet(f\"{path_to_als_model}/userFactors\")\n",
    "    item_factors = spark.read.parquet(f\"{path_to_als_model}/itemFactors\")\n",
    "\n",
    "    print(\"✅ SUCCÈS ! Les userFactors et itemFactors ont été chargés manuellement.\")\n",
    "\n",
    "    print(\"Aperçu des userFactors :\")\n",
    "    user_factors.show(5)\n",
    "\n",
    "    print(\"Aperçu des itemFactors :\")\n",
    "    item_factors.show(5)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ ERREUR lors du chargement manuel des facteurs.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bafcd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des DataFrames préparés (test_data, df_movies_cleaned) et du modèle ALS global...\n",
      "Erreur lors du chargement des fichiers ou du modèle : name 'os' is not defined\n",
      "Vérifiez que les fichiers Parquet et le modèle ALS ont bien été sauvegardés.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# --- Chargement des DataFrames préparés et du modèle ALS ---\n",
    "print(\"Chargement des DataFrames préparés (test_data, df_movies_cleaned) et du modèle ALS global...\")\n",
    "output_dir = rf\"file:///C:\\Users\\arthu\\Desktop\\spank movies\\ml-32m\\data\"   # Dossier des DataFrames Parquet\n",
    "models_dir = rf\"file:///C:\\Users\\arthu\\Desktop\\spank movies\\ml-32m\\models\" # Dossier du modèle ALS sauvegardé\n",
    "\n",
    "try:\n",
    "    test_data = spark.read.parquet(os.path.join(output_dir, \"test_data.parquet\"))\n",
    "    df_movies_cleaned = spark.read.parquet(os.path.join(output_dir, \"df_movies_cleaned.parquet\"))\n",
    "    best_model_global = ALSModel.load(os.path.join(models_dir, \"best_als_global_model\"))\n",
    "    print(\"DataFrames et modèle ALS chargés avec succès.\")\n",
    "\n",
    "    # Vérification rapide des schémas\n",
    "    print(\"\\nSchéma de test_data:\")\n",
    "    test_data.printSchema()\n",
    "    print(\"\\nSchéma de df_movies_cleaned:\")\n",
    "    df_movies_cleaned.printSchema()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des fichiers ou du modèle : {e}\")\n",
    "    print(\"Vérifiez que les fichiers Parquet et le modèle ALS ont bien été sauvegardés.\")\n",
    "    spark.stop()\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97683438",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model_global' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Préparation des facteurs latents des utilisateurs pour KNN ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# userFactors contient userId et un vecteur de facteurs latents (features)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m user_factors_df = \u001b[43mbest_model_global\u001b[49m.userFactors\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# CORRECTION CLÉ : Renommer la colonne 'id' en 'userId' dans user_factors_df\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Ceci est crucial car userFactors utilise 'id' par défaut, mais le reste de notre code utilise 'userId'.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m user_factors_df.columns \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muserId\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m user_factors_df.columns:\n",
      "\u001b[31mNameError\u001b[39m: name 'best_model_global' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# --- Préparation des facteurs latents des utilisateurs pour KNN ---\n",
    "# userFactors contient userId et un vecteur de facteurs latents (features)\n",
    "user_factors_df = best_model_global.userFactors\n",
    "\n",
    "# CORRECTION CLÉ : Renommer la colonne 'id' en 'userId' dans user_factors_df\n",
    "# Ceci est crucial car userFactors utilise 'id' par défaut, mais le reste de notre code utilise 'userId'.\n",
    "if \"id\" in user_factors_df.columns and \"userId\" not in user_factors_df.columns:\n",
    "    user_factors_df = user_factors_df.withColumnRenamed(\"id\", \"userId\")\n",
    "\n",
    "print(\"\\nSchéma de user_factors_df (après renommage si nécessaire):\")\n",
    "user_factors_df.printSchema()\n",
    "user_factors_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Définition de la fonction de similarité Cosinus (UDF) ---\n",
    "@udf(returnType=DoubleType())\n",
    "def cosine_similarity(features1, features2):\n",
    "    if features1 is None or features2 is None:\n",
    "        return None\n",
    "    vec1 = np.array(features1)\n",
    "    vec2 = np.array(features2)\n",
    "    dot_product = float(np.dot(vec1, vec2))\n",
    "    norm_a = float(np.linalg.norm(vec1))\n",
    "    norm_b = float(np.linalg.norm(vec2))\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0.0 # Éviter la division par zéro\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fonction pour trouver les K utilisateurs les plus similaires ---\n",
    "def find_k_nearest_neighbors(target_user_id, k, user_factors_df_param):\n",
    "    \"\"\"\n",
    "    Trouve les K utilisateurs les plus similaires à un utilisateur cible\n",
    "    basé sur la similarité cosinus de leurs facteurs latents.\n",
    "    \"\"\"\n",
    "    target_user_features_row = user_factors_df_param.filter(col(\"userId\") == target_user_id).select(\"features\").first()\n",
    "    \n",
    "    if not target_user_features_row:\n",
    "        print(f\"Facteurs latents non trouvés pour l'utilisateur {target_user_id}. Vérifiez si l'utilisateur existe dans le modèle.\")\n",
    "        return spark.createDataFrame([], \"userId INT, similarity DOUBLE\")\n",
    "\n",
    "    target_features = target_user_features_row['features']\n",
    "\n",
    "    # Calculer la similarité avec tous les autres utilisateurs\n",
    "    similarities_df = user_factors_df_param \\\n",
    "        .filter(col(\"userId\") != target_user_id) \\\n",
    "        .withColumn(\"similarity\", cosine_similarity(lit(target_features), col(\"features\"))) \\\n",
    "        .filter(col(\"similarity\").isNotNull()) \\\n",
    "        .orderBy(col(\"similarity\").desc()) \\\n",
    "        .limit(k) \\\n",
    "        .select(\"userId\", \"similarity\")\n",
    "\n",
    "    return similarities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fonction pour recommander des films basés sur les K voisins ---\n",
    "def recommend_movies_knn(target_user_id, k_neighbors, df_ratings_param, df_movies_cleaned_param, user_factors_df_param, k_recs=10):\n",
    "    \"\"\"\n",
    "    Recommande des films à un utilisateur en se basant sur les notes de ses K voisins les plus proches.\n",
    "    \"\"\"\n",
    "    print(f\"Recherche des {k_neighbors} voisins les plus proches pour l'utilisateur {target_user_id}...\")\n",
    "    neighbors_df = find_k_nearest_neighbors(target_user_id, k_neighbors, user_factors_df_param)\n",
    "    \n",
    "    if neighbors_df.count() == 0:\n",
    "        print(f\"Aucun voisin trouvé ou pas assez de voisins pour l'utilisateur {target_user_id}.\")\n",
    "        return spark.createDataFrame([], \"title STRING, genres STRING, predicted_score_knn DOUBLE\")\n",
    "\n",
    "    # Récupérer les notes des films par les voisins\n",
    "    neighbor_ratings = df_ratings_param.join(neighbors_df, on=\"userId\", how=\"inner\")\n",
    "\n",
    "    # Pour éviter de recommander des films déjà vus par l'utilisateur cible (dans training_data, qui contient df_ratings complet)\n",
    "    # df_ratings_param est votre df_ratings original complet, donc on filtre les films que l'utilisateur \n",
    "    # a pu noter historiquement.\n",
    "    movies_seen_by_target = df_ratings_param.filter(col(\"userId\") == target_user_id).select(\"movieId\").distinct()\n",
    "\n",
    "    # Films notés par les voisins et non vus par l'utilisateur cible\n",
    "    candidate_movies = neighbor_ratings.join(movies_seen_by_target, on=\"movieId\", how=\"left_anti\")\n",
    "\n",
    "    if candidate_movies.count() == 0:\n",
    "        print(f\"Pas de films candidats uniques à recommander pour l'utilisateur {target_user_id} après filtrage des films déjà vus.\")\n",
    "        return spark.createDataFrame([], \"title STRING, genres STRING, predicted_score_knn DOUBLE\")\n",
    "\n",
    "    # Calcul du score pondéré pour chaque film candidat\n",
    "    weighted_scores = candidate_movies.groupBy(\"movieId\") \\\n",
    "        .agg((sum(col(\"rating\") * col(\"similarity\")) / sum(col(\"similarity\"))).alias(\"predicted_score_knn\"))\n",
    "\n",
    "    # Joindre avec les titres de films et trier\n",
    "    recommendations = weighted_scores.join(df_movies_cleaned_param, on=\"movieId\", how=\"inner\") \\\n",
    "        .orderBy(col(\"predicted_score_knn\").desc()) \\\n",
    "        .limit(k_recs) \\\n",
    "        .select(\"title\", \"genres\", \"predicted_score_knn\")\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Génération et affichage des recommandations KNN pour utilisateurs fictifs ---\n",
    "print(\"\\n--- Génération des recommandations KNN pour des utilisateurs fictifs ---\")\n",
    "users_to_recommend = [50, 150, 250, 350, 450] # Les mêmes utilisateurs que précédemment\n",
    "K_NEIGHBORS = 50  # Nombre de voisins à considérer pour KNN\n",
    "K_RECOMMENDATIONS = 10 # Nombre de films à recommander\n",
    "\n",
    "# Pour la fonction recommend_movies_knn, nous devons passer df_ratings original (complet)\n",
    "# pour que le filtrage des films déjà vus fonctionne sur toutes les notes de l'utilisateur.\n",
    "# Attention, df_ratings n'est pas passé comme paramètre dans le main de ce notebook,\n",
    "# il faut le charger ou s'assurer qu'il est dans le scope. Pour éviter des problèmes,\n",
    "# on va le recharger ici explicitement si le scope n'est pas clair.\n",
    "# Ou mieux, passer training_data + test_data combiné comme df_ratings_full.\n",
    "# La solution la plus simple est de recharger df_ratings si nécessaire ici.\n",
    "\n",
    "# Charger df_ratings à nouveau pour l'usage dans recommend_movies_knn pour filtrer les films vus\n",
    "# (car recommend_movies_knn attend df_ratings_param, qui représente l'historique complet des notes)\n",
    "try:\n",
    "    df_ratings_full_for_knn = spark.read.csv(\"ratings.csv\", header=True, inferSchema=True)\n",
    "    # Appliquer le même nettoyage que dans 01_data_analysis_and_preparation.ipynb\n",
    "    df_ratings_full_for_knn = df_ratings_full_for_knn.na.drop().dropDuplicates(['userId', 'movieId', 'timestamp'])\n",
    "    print(\"df_ratings complet rechargé et nettoyé pour la fonction KNN.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du rechargement de df_ratings complet pour KNN : {e}\")\n",
    "    df_ratings_full_for_knn = None # Gérer si le chargement échoue\n",
    "\n",
    "if df_ratings_full_for_knn is not None:\n",
    "    for user_id in users_to_recommend:\n",
    "        print(f\"\\n================== RECOMMANDATIONS KNN POUR L'UTILISATEUR {user_id} ==================\")\n",
    "        # Passez df_ratings_full_for_knn comme paramètre 'df_ratings_param'\n",
    "        knn_recs = recommend_movies_knn(\n",
    "            user_id, K_NEIGHBORS, df_ratings_full_for_knn, df_movies_cleaned, user_factors_df, K_RECOMMENDATIONS\n",
    "        )\n",
    "        if knn_recs.count() > 0:\n",
    "            knn_recs.show(truncate=False)\n",
    "        else:\n",
    "            print(f\"Pas de recommandations trouvées pour l'utilisateur {user_id} après filtrage.\")\n",
    "else:\n",
    "    print(\"Impossible de générer les recommandations KNN car df_ratings complet n'a pas pu être chargé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calcul des métriques de Précision@K et Rappel@K pour KNN ---\n",
    "print(\"\\n--- Calcul des métriques de Précision@K et Rappel@K pour KNN ---\")\n",
    "\n",
    "# Déjà défini dans le notebook 02, mais la fonction est répétée ici pour l'évaluation\n",
    "# du KNN spécifiquement.\n",
    "def calculate_precision_recall(recs_df, actual_df, k_val):\n",
    "    joined_df = recs_df.join(actual_df, on=\"userId\", how=\"inner\")\n",
    "\n",
    "    hits_df = joined_df.withColumn(\n",
    "        \"hits\",\n",
    "        size(array_intersect(col(\"recommended_movies\"), col(\"actual_movies\")))\n",
    "    )\n",
    "\n",
    "    precision_at_k_df = hits_df.withColumn(\n",
    "        \"precision_at_k\",\n",
    "        col(\"hits\") / lit(k_val)\n",
    "    )\n",
    "\n",
    "    recall_at_k_df = precision_at_k_df.withColumn(\n",
    "        \"recall_at_k\",\n",
    "        when(size(col(\"actual_movies\")) > 0, col(\"hits\") / size(col(\"actual_movies\"))).otherwise(0.0)\n",
    "    )\n",
    "    \n",
    "    # Filter out users with no actual movies in test set before averaging\n",
    "    recall_at_k_df = recall_at_k_df.filter(size(col(\"actual_movies\")) > 0)\n",
    "    \n",
    "    if recall_at_k_df.count() == 0:\n",
    "        return 0.0, 0.0 # Retourne 0 si aucun utilisateur valide pour l'évaluation\n",
    "\n",
    "    avg_precision = recall_at_k_df.agg(sum(\"precision_at_k\")).first()[0] / recall_at_k_df.count()\n",
    "    avg_recall = recall_at_k_df.agg(sum(\"recall_at_k\")).first()[0] / recall_at_k_df.count()\n",
    "\n",
    "    return avg_precision, avg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b18f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les films réels notés par chaque utilisateur dans le jeu de test (vérité terrain)\n",
    "# C'est 'test_data' qui contient les films réels à comparer.\n",
    "actual_ratings_per_user_test = test_data.groupBy(\"userId\").agg(\n",
    "    collect_list(\"movieId\").alias(\"actual_movies\")\n",
    ")\n",
    "\n",
    "# Nous devons générer les recommandations KNN pour TOUS les utilisateurs du test_data\n",
    "# qui sont également présents dans user_factors_df.\n",
    "# C'est l'étape la plus coûteuse pour KNN en mode \"évaluation globale\".\n",
    "# Pour des millions d'utilisateurs, une UDTF ou une approche batch plus complexe serait nécessaire.\n",
    "# Pour l'instant, nous allons nous limiter à un échantillon significatif du test_data si c'est trop lent.\n",
    "\n",
    "# Filtrer les utilisateurs du test_data qui ont des facteurs latents (connus du modèle ALS)\n",
    "users_for_knn_eval = actual_ratings_per_user_test.join(user_factors_df.select(\"userId\"), on=\"userId\", how=\"inner\")\n",
    "\n",
    "# Pour des raisons de performance, nous allons prendre un échantillon d'utilisateurs pour l'évaluation KNN\n",
    "# Si vous avez une machine puissante, vous pouvez commenter la ligne .limit(1000)\n",
    "users_for_knn_eval_sample = users_for_knn_eval.limit(1000) # Évalue KNN sur 1000 utilisateurs du test set\n",
    "\n",
    "knn_recs_for_eval = []\n",
    "print(f\"\\nPréparation des recommandations KNN pour {users_for_knn_eval_sample.count()} utilisateurs pour l'évaluation...\")\n",
    "for row in users_for_knn_eval_sample.collect():\n",
    "    user_id = row.userId\n",
    "    # Notez que j'appelle recommend_movies_knn et que je lui passe les DataFrames nécessaires\n",
    "    recs_df = recommend_movies_knn(user_id, K_NEIGHBORS, df_ratings_full_for_knn, df_movies_cleaned, user_factors_df, K_EVAL)\n",
    "    if recs_df.count() > 0:\n",
    "        # Récupérer seulement les movieId pour la comparaison\n",
    "        recommended_movie_ids = recs_df.join(df_movies_cleaned.select(\"movieId\", \"title\"), on=\"title\", how=\"inner\").select(\"movieId\").rdd.flatMap(lambda x: x).collect()\n",
    "        knn_recs_for_eval.append((user_id, recommended_movie_ids))\n",
    "    else:\n",
    "        knn_recs_for_eval.append((user_id, [])) # Pas de recommandations\n",
    "\n",
    "knn_recs_eval_df = spark.createDataFrame(knn_recs_for_eval, [\"userId\", \"recommended_movies\"])\n",
    "\n",
    "# Calcul des métriques KNN\n",
    "knn_precision, knn_recall = calculate_precision_recall(\n",
    "    knn_recs_eval_df, actual_ratings_per_user_test, K_EVAL\n",
    ")\n",
    "print(f\"KNN : Precision@{K_EVAL} = {knn_precision:.4f}, Recall@{K_EVAL} = {knn_recall:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d342b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Arrêt de la SparkSession ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Arrêt de la SparkSession ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Arrêt de la SparkSession ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mspark\u001b[49m.stop()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Script 03_knn_recommendations.ipynb Terminé ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Arrêt de la SparkSession ---\n",
    "print(\"\\n--- Arrêt de la SparkSession ---\")\n",
    "spark.stop()\n",
    "\n",
    "print(\"\\n--- Script 03_knn_recommendations.ipynb Terminé ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
