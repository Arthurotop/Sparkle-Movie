{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c457358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "02_als_modeling_and_recommendations.ipynb\n",
    "\n",
    "Ce notebook est dédié à la modélisation ALS pour les recommandations de films.\n",
    "Il entraîne deux modèles ALS (un global, un sur les films récents),\n",
    "effectue un Grid Search pour l'optimisation des hyperparamètres,\n",
    "et évalue leur performance.\n",
    "\"\"\"\n",
    "\n",
    "# Importations nécessaires\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, sum, when, lit, collect_list\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8803649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage de la SparkSession pour la modélisation ALS ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Initialisation de la SparkSession ---\n",
    "print(\"--- Démarrage de la SparkSession pour la modélisation ALS ---\")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ALSModeling\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.maxResults\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1645f9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des DataFrames préparés (training_data, test_data, df_movies_cleaned)...\n",
      "DataFrames chargés avec succès.\n",
      "\n",
      "Schéma et 5 premières lignes de training_data:\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    260|   5.0| 943228696|\n",
      "|     3|   7143|   4.0|1084485499|\n",
      "|     6|   2949|   5.0|1100060102|\n",
      "|     9|   1639|   3.5|1138474089|\n",
      "|    10|   2231|   3.5|1190332092|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Schéma et 5 premières lignes de test_data:\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|    16|  84374|   3.0|1572741045|\n",
      "|    20|     32|   4.0|1553187324|\n",
      "|    20|   1193|   5.0|1553181212|\n",
      "|    23|  85414|   4.0|1570190129|\n",
      "|    28| 208108|   4.0|1661809465|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Schéma et 5 premières lignes de df_movies_cleaned:\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+------------+\n",
      "|movieId|               title|              genres|release_year|\n",
      "+-------+--------------------+--------------------+------------+\n",
      "|      1|           Toy Story|Adventure|Animati...|        1995|\n",
      "|      2|             Jumanji|Adventure|Childre...|        1995|\n",
      "|      3|    Grumpier Old Men|      Comedy|Romance|        1995|\n",
      "|      4|   Waiting to Exhale|Comedy|Drama|Romance|        1995|\n",
      "|      5|Father of the Bri...|              Comedy|        1995|\n",
      "+-------+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Chargement des DataFrames préparés ---\n",
    "print(\"Chargement des DataFrames préparés (training_data, test_data, df_movies_cleaned)...\")\n",
    "output_dir = \"data\" # Assurez-vous que ce chemin correspond à celui du notebook précédent\n",
    "\n",
    "try:\n",
    "    training_data = spark.read.parquet(os.path.join(output_dir, \"training_data.parquet\"))\n",
    "    test_data = spark.read.parquet(os.path.join(output_dir, \"test_data.parquet\"))\n",
    "    df_movies_cleaned = spark.read.parquet(os.path.join(output_dir, \"df_movies_cleaned.parquet\"))\n",
    "    print(\"DataFrames chargés avec succès.\")\n",
    "    \n",
    "    # Vérification rapide des données chargées\n",
    "    print(\"\\nSchéma et 5 premières lignes de training_data:\")\n",
    "    training_data.printSchema()\n",
    "    training_data.show(5)\n",
    "    print(\"\\nSchéma et 5 premières lignes de test_data:\")\n",
    "    test_data.printSchema()\n",
    "    test_data.show(5)\n",
    "    print(\"\\nSchéma et 5 premières lignes de df_movies_cleaned:\")\n",
    "    df_movies_cleaned.printSchema()\n",
    "    df_movies_cleaned.show(5)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des fichiers Parquet : {e}\")\n",
    "    print(\"Vérifiez que les fichiers Parquet ont bien été sauvegardés dans le dossier 'data/' par le notebook 01.\")\n",
    "    print(\"Le problème HADOOP_HOME doit être résolu pour cette étape.\")\n",
    "    spark.stop()\n",
    "    exit() # Quitte le script si les données ne peuvent pas être chargées\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73d8d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Modèle ALS (Global - sur toutes les données d'entraînement) ---\n",
      "Lancement du Grid Search pour le modèle ALS global (peut prendre du temps)...\n",
      "\n",
      "Meilleurs hyperparamètres pour ALS Global - Rank: 20, RegParam: 0.1, MaxIter: 10\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration commune pour ALS et l'évaluation ---\n",
    "user_col = \"userId\"\n",
    "item_col = \"movieId\"\n",
    "rating_col = \"rating\"\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=rating_col, predictionCol=\"prediction\")\n",
    "\n",
    "# --- Modèle ALS 1: Sur l'intégralité des données (training_data) ---\n",
    "print(\"\\n--- Modèle ALS (Global - sur toutes les données d'entraînement) ---\")\n",
    "\n",
    "als_global = ALS(\n",
    "    userCol=user_col,\n",
    "    itemCol=item_col,\n",
    "    ratingCol=rating_col,\n",
    "    coldStartStrategy=\"drop\", # Gère les utilisateurs/films non vus dans le train set lors de la prédiction\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Définition de la grille de paramètres pour le Grid Search du modèle global\n",
    "# Ces valeurs sont des points de départ. Ajustez selon vos ressources et le temps disponible.\n",
    "param_grid_global = ParamGridBuilder() \\\n",
    "    .addGrid(als_global.rank, [10, 20]) \\\n",
    "    .addGrid(als_global.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(als_global.maxIter, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "cross_validator_global = CrossValidator(\n",
    "    estimator=als_global,\n",
    "    estimatorParamMaps=param_grid_global,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3, # Réduit le nombre de plis pour accélérer, mais 5 est plus robuste\n",
    "    seed=42,\n",
    "    parallelism=4 # Ajustez selon le nombre de cœurs de votre machine/cluster\n",
    ")\n",
    "\n",
    "print(\"Lancement du Grid Search pour le modèle ALS global (peut prendre du temps)...\")\n",
    "cv_model_global = cross_validator_global.fit(training_data)\n",
    "best_model_global = cv_model_global.bestModel\n",
    "\n",
    "print(f\"\\nMeilleurs hyperparamètres pour ALS Global - Rank: {best_model_global._java_obj.parent().getRank()}, RegParam: {best_model_global._java_obj.parent().getRegParam()}, MaxIter: {best_model_global._java_obj.parent().getMaxIter()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4653d398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE du meilleur modèle ALS Global sur le jeu de test : 0.8327\n",
      "\n",
      "Meilleur modèle ALS Global sauvegardé à : models\\best_als_global_model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Évaluation du meilleur modèle ALS global sur le jeu de test\n",
    "predictions_global = best_model_global.transform(test_data)\n",
    "rmse_global = evaluator.evaluate(predictions_global.na.drop()) # Suppression des NaN pour le calcul RMSE\n",
    "\n",
    "print(f\"RMSE du meilleur modèle ALS Global sur le jeu de test : {rmse_global:.4f}\")\n",
    "\n",
    "# --- Sauvegarde du modèle ALS Global (utilisé plus tard pour KNN) ---\n",
    "models_dir = \"models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "best_model_global_path = os.path.join(models_dir, \"best_als_global_model\")\n",
    "best_model_global.save(best_model_global_path)\n",
    "print(f\"\\nMeilleur modèle ALS Global sauvegardé à : {best_model_global_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058de937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Modèle ALS (Films depuis 2018) ---\n",
      "Lancement du Grid Search pour le modèle ALS sur les films récents (peut prendre du temps)...\n",
      "\n",
      "Meilleurs hyperparamètres pour ALS (Films depuis 2018) - Rank: 15, RegParam: 0.15, MaxIter: 10\n",
      "RMSE du meilleur modèle ALS (Films depuis 2018) sur le jeu de test récent : 2.6274\n"
     ]
    }
   ],
   "source": [
    "# --- Modèle ALS 2: Sur les films depuis 2018 ---\n",
    "print(\"\\n--- Modèle ALS (Films depuis 2018) ---\")\n",
    "\n",
    "# 1. Filtrer les notes pour n'inclure que les films sortis depuis 2018\n",
    "# Joindre training_data avec df_movies_cleaned pour obtenir l'année de sortie\n",
    "training_data_recent_movies = training_data.join(\n",
    "    df_movies_cleaned.filter(col(\"release_year\") >= 2018).select(\"movieId\", \"release_year\"),\n",
    "    on=\"movieId\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "# Assurez-vous que le DataFrame filtré n'est pas vide\n",
    "if training_data_recent_movies.count() == 0:\n",
    "    print(\"ATTENTION: Aucun film sorti depuis 2018 trouvé dans le jeu d'entraînement. Impossible d'entraîner le modèle récent.\")\n",
    "else:\n",
    "    als_recent = ALS(\n",
    "        userCol=user_col,\n",
    "        itemCol=item_col,\n",
    "        ratingCol=rating_col,\n",
    "        coldStartStrategy=\"drop\",\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Définition de la grille de paramètres pour le Grid Search du modèle récent\n",
    "    param_grid_recent = ParamGridBuilder() \\\n",
    "        .addGrid(als_recent.rank, [8, 15]) \\\n",
    "        .addGrid(als_recent.regParam, [0.05, 0.15]) \\\n",
    "        .addGrid(als_recent.maxIter, [5, 10]) \\\n",
    "        .build()\n",
    "\n",
    "    cross_validator_recent = CrossValidator(\n",
    "        estimator=als_recent,\n",
    "        estimatorParamMaps=param_grid_recent,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=3,\n",
    "        seed=42,\n",
    "        parallelism=4\n",
    "    )\n",
    "\n",
    "    print(\"Lancement du Grid Search pour le modèle ALS sur les films récents (peut prendre du temps)...\")\n",
    "    cv_model_recent = cross_validator_recent.fit(training_data_recent_movies)\n",
    "    best_model_recent = cv_model_recent.bestModel\n",
    "\n",
    "    print(f\"\\nMeilleurs hyperparamètres pour ALS (Films depuis 2018) - Rank: {best_model_recent._java_obj.parent().getRank()}, RegParam: {best_model_recent._java_obj.parent().getRegParam()}, MaxIter: {best_model_recent._java_obj.parent().getMaxIter()}\")\n",
    "\n",
    "    # Évaluation du meilleur modèle ALS récent sur un sous-ensemble du jeu de test (films récents)\n",
    "    test_data_recent_movies = test_data.join(\n",
    "        df_movies_cleaned.filter(col(\"release_year\") >= 2018).select(\"movieId\", \"release_year\"),\n",
    "        on=\"movieId\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    if test_data_recent_movies.count() > 0:\n",
    "        predictions_recent = best_model_recent.transform(test_data_recent_movies)\n",
    "        rmse_recent = evaluator.evaluate(predictions_recent.na.drop())\n",
    "        print(f\"RMSE du meilleur modèle ALS (Films depuis 2018) sur le jeu de test récent : {rmse_recent:.4f}\")\n",
    "    else:\n",
    "        print(\"Pas de films récents dans le jeu de test pour évaluer le modèle récent.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97d7e472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Génération des recommandations ALS pour des utilisateurs fictifs ---\n",
      "\n",
      "================== RECOMMANDATIONS ALS POUR L'UTILISATEUR 50 ==================\n",
      "                        title                  genres  prediction\n",
      "                    The Thorn                  Comedy    6.290634\n",
      "                      Acı Aşk                   Drama    6.112364\n",
      "                  Head Trauma Horror|Mystery|Thriller    5.621753\n",
      "              Catch That Girl         Action|Children    5.579004\n",
      "                            2                   Drama    5.528359\n",
      " Life Even Looks Like a Party             Documentary    5.379093\n",
      "             Shivering Trunks      (no genres listed)    5.337296\n",
      "                         Loot            Comedy|Crime    5.336211\n",
      "Christmas on Salvation Street      (no genres listed)    5.328463\n",
      "        Story of Science, The             Documentary    5.317255\n",
      "\n",
      "================== RECOMMANDATIONS ALS POUR L'UTILISATEUR 450 ==================\n",
      "                                     title             genres  prediction\n",
      "                                   Acı Aşk              Drama    6.009206\n",
      "                                 The Thorn             Comedy    5.620848\n",
      "                                      Loot       Comedy|Crime    5.365994\n",
      "                      Heroes Shed No Tears             Action    5.202006\n",
      "Seeing Red: Stories of American Communists (no genres listed)    5.168456\n",
      "                           Catch That Girl    Action|Children    5.151660\n",
      "                          American Teacher        Documentary    5.114677\n",
      "                    Lagerfeld Confidential        Documentary    5.108876\n",
      "                            Hello Stranger              Drama    5.093839\n",
      "                     Story of Science, The        Documentary    5.087346\n",
      "\n",
      "================== RECOMMANDATIONS ALS POUR L'UTILISATEUR 150 ==================\n",
      "                                                    title                  genres  prediction\n",
      "                                                The Thorn                  Comedy    6.150195\n",
      "                                                  Acı Aşk                   Drama    5.831636\n",
      "                                              Head Trauma Horror|Mystery|Thriller    5.572717\n",
      "                                          Catch That Girl         Action|Children    5.196958\n",
      "                                  Who Killed Chea Vichea?             Documentary    5.195594\n",
      "                            Christmas on Salvation Street      (no genres listed)    5.194641\n",
      "                                   The Marriage of Figaro                  Comedy    5.158210\n",
      "                                  Cari fottutissimi amici                  Comedy    5.148454\n",
      "                            Wolfguy - Enraged Lycanthrope           Action|Horror    5.129218\n",
      "Santa Claus Has Blue Eyes (Le père Noël a les yeux bleus)                   Drama    5.129190\n",
      "\n",
      "================== RECOMMANDATIONS ALS POUR L'UTILISATEUR 250 ==================\n",
      "                                                  title              genres  prediction\n",
      "                                                Acı Aşk               Drama    6.860057\n",
      "                                              The Thorn              Comedy    6.442144\n",
      "                                                   Loot        Comedy|Crime    5.979525\n",
      "                                     The Country Cousin           Animation    5.826600\n",
      "             Seeing Red: Stories of American Communists  (no genres listed)    5.800530\n",
      "                                   Heroes Shed No Tears              Action    5.766662\n",
      "                                 Lagerfeld Confidential         Documentary    5.711310\n",
      "                                  Story of Science, The         Documentary    5.698391\n",
      "                                         Hello Stranger               Drama    5.638179\n",
      "2013 Rock and Roll Hall of Fame Induction Ceremony, The Documentary|Musical    5.575766\n",
      "\n",
      "================== RECOMMANDATIONS ALS POUR L'UTILISATEUR 350 ==================\n",
      "                  title                    genres  prediction\n",
      "              The Thorn                    Comedy    5.703425\n",
      "                Acı Aşk                     Drama    5.702595\n",
      "     The Country Cousin                 Animation    5.006718\n",
      "The Wearing of the Grin                 Animation    4.924664\n",
      "            Head Trauma   Horror|Mystery|Thriller    4.912452\n",
      "                   Loot              Comedy|Crime    4.815845\n",
      " Hellhounds on My Trail               Documentary    4.777104\n",
      "           Interruption                     Drama    4.749646\n",
      "      Porky's Hare Hunt Animation|Children|Comedy    4.728715\n",
      "          Neue Vahr Süd                    Comedy    4.701335\n"
     ]
    }
   ],
   "source": [
    "# --- Génération et affichage des recommandations ALS ---\n",
    "# Nous allons utiliser le best_model_global pour générer les recommandations pour les utilisateurs fictifs,\n",
    "# car c'est le modèle le plus complet.\n",
    "\n",
    "print(\"\\n--- Génération des recommandations ALS pour des utilisateurs fictifs ---\")\n",
    "users_to_recommend = [50, 150, 250, 350, 450] # Les mêmes utilisateurs que précédemment\n",
    "\n",
    "# Créer un DataFrame des utilisateurs pour lesquels générer des recommandations\n",
    "users_df = spark.createDataFrame([(user_id,) for user_id in users_to_recommend], [\"userId\"])\n",
    "\n",
    "# Générer les 10 meilleures recommandations pour ces utilisateurs\n",
    "# S'assure que les utilisateurs existent bien dans le userFactors du modèle\n",
    "users_in_model_factors = best_model_global.userFactors.withColumnRenamed(\"id\", \"userId\").select(\"userId\").distinct()\n",
    "users_to_recommend_filtered = users_df.join(users_in_model_factors, on=\"userId\", how=\"inner\")\n",
    "\n",
    "if users_to_recommend_filtered.count() == 0:\n",
    "    print(\"Aucun des utilisateurs fictifs n'est présent dans le modèle ALS global. Impossible de générer des recommandations.\")\n",
    "else:\n",
    "    # Obtenir les recommandations ALS\n",
    "    als_recommendations = best_model_global.recommendForUserSubset(users_to_recommend_filtered, 10)\n",
    "\n",
    "    # Filtrer les films déjà vus par les utilisateurs dans le jeu d'entraînement pour des recommandations plus réalistes\n",
    "    # (Bien que ALS.recommendForUserSubset tente de faire cela, une vérification explicite peut être utile)\n",
    "    \n",
    "    # Pour chaque utilisateur, récupérer les films qu'il a déjà vus dans training_data\n",
    "    seen_movies_by_user = training_data.withColumnRenamed(\"id\", \"userId\").groupBy(\"userId\").agg(collect_list(\"movieId\").alias(\"seen_movies\"))\n",
    "\n",
    "    # Convertir les recommandations en un format plus facile à manipuler\n",
    "    # Assurez-vous que la colonne 'recommendations' contient des structs avec 'movieId'\n",
    "    # Renommer la colonne 'id' en 'userId' dans userFactors si nécessaire (vérification faite dans le notebook 03)\n",
    "    \n",
    "    # Processus pour afficher les recommandations individuelles\n",
    "    for row in als_recommendations.collect():\n",
    "        user_id = row.userId\n",
    "        recs = row.recommendations\n",
    "\n",
    "        # Extraire les movieIds des recommandations\n",
    "        recommended_movie_ids = [r.movieId for r in recs]\n",
    "        \n",
    "        # Récupérer les titres et genres des films recommandés\n",
    "        recommended_movies_details = df_movies_cleaned.filter(col(\"movieId\").isin(recommended_movie_ids)) \\\n",
    "            .select(\"movieId\", \"title\", \"genres\").toPandas()\n",
    "        \n",
    "        # Ajouter la prédiction de rating pour chaque film recommandé\n",
    "        # Créer un dictionnaire pour mapper movieId à prediction\n",
    "        prediction_map = {r.movieId: r.rating for r in recs}\n",
    "        recommended_movies_details['prediction'] = recommended_movies_details['movieId'].map(prediction_map)\n",
    "\n",
    "        # Trier par la prédiction ALS et afficher\n",
    "        recommended_movies_details = recommended_movies_details.sort_values(by='prediction', ascending=False)\n",
    "        \n",
    "        print(f\"\\n================== RECOMMANDATIONS ALS POUR L'UTILISATEUR {user_id} ==================\")\n",
    "        print(recommended_movies_details[['title', 'genres', 'prediction']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4060b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Arrêt de la SparkSession ---\n",
    "print(\"\\n--- Arrêt de la SparkSession ---\")\n",
    "spark.stop()\n",
    "\n",
    "print(\"\\n--- Script 02_als_modeling_and_recommendations.ipynb Terminé ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
